{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\newcommand{P}[1]{\\mathrm{P}\\left( #1 \\right)}\n",
    "\\newcommand{Pc}[2]{\\mathrm{P}\\left( #1 \\mid #2 \\right)}\n",
    "\\newcommand{Ec}[2]{\\mathrm{E}\\left( #1 \\mid #2 \\right)}\n",
    "\\newcommand{In}[2]{ #1 \\perp\\!\\!\\!\\perp #2}\n",
    "\\newcommand{Cin}[3]{ #1 \\perp\\!\\!\\!\\perp #2 \\, | \\, #3}\n",
    "\\newcommand{do}[1]{\\mathrm{do}\\left( #1 \\right)}\n",
    "\\newcommand{\\ind}{\\perp\\!\\!\\!\\!\\perp}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causal Inference\n",
    "\n",
    "Day 3 Module 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Associatiioon and Causality\n",
    "\n",
    "* $X$ causes $Y$ $\\Rightarrow$ $X$ and $Y$ are associated\n",
    "\n",
    "* $X$ causes $Y$ $\\nLeftarrow$ $X$ and $Y$ are associated\n",
    "\n",
    "![no_causation](./plots/causal1.jpg)\n",
    "\n",
    "* Observational Data $\\implies$ outcome comparison between treatment and control $\\implies$ Association\n",
    "\n",
    "* RCT $\\implies$ outcome comparison between treatment and control $\\implies$ Causation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![spurious_corr_demo](./plots/chocolate1.png)\n",
    "\n",
    "##### [More on spurious correlation](https://www.tylervigen.com/spurious-correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Simpson's Paradox\n",
    "\n",
    "[Simpson' Paradox](https://en.wikipedia.org/wiki/Simpson%27s_paradox) is a example of one of the counter intuitive properties of probability distributions.\n",
    "\n",
    "As an example of the paradox, imagine we are trying to find out whether certain treatment is effective for a disease. We decide to compare people who received the treatment versus who did not. \n",
    "\n",
    "Let $A$ be a binary treatment variable (trt) with $A=1$ if the subject received treatment and $A=0$ if the subject was assigned to the control group.  \n",
    "$Y$ be a binary outcome variable, $Y=1$ if the subject is cured and $Y=0$ if not. We further denote $X$ be a third confounding variable (e.g. sex), $X=1$ for female and $X=0$ for male.\n",
    "\n",
    "Unfortunately, this drug was not administered as part of a [random controlled trial](https://en.wikipedia.org/wiki/Randomized_controlled_trial). Instead, we observed the following data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   count  trt  y  sex\n",
      "0    131    0  1    0\n",
      "1     56    0  0    0\n",
      "2     19    0  1    1\n",
      "3     44    0  0    1\n",
      "4     50    1  1    0\n",
      "5     12    1  0    0\n",
      "6     75    1  1    1\n",
      "7    113    1  0    1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "df = pd.read_csv(\"eg.simpsons.csv\")\n",
    "HTML(print(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To decide whether it is effective, we compare the percentage of people who were cured among the treatment group versus the percentage of cured among the control group. i.e. the treatment effect can be defined as $P(Y=1|A=1) - P(Y=1|A=0)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treatment effect for subgroup sex= 0  is  0.106\n",
      "treatment effect for subgroup sex= 1  is  0.097\n",
      "treatment effect for the entire cohort is  -0.100\n"
     ]
    }
   ],
   "source": [
    "for sex in sorted(df.sex.unique()):\n",
    "    d = df[df.sex == sex].set_index([\"trt\", \"y\"])[\"count\"].to_dict()\n",
    "    n0 = int(d[(0,0)] + d[(0,1)])\n",
    "    p0 = d[(0,1)] / n0 if n0 != 0 else 0\n",
    "    n1 = int(d[(1,0)] + d[(1,1)])\n",
    "    p1 = d[(1,1)] / n1 if n1 != 0 else 0\n",
    "    dp = \"{:.3f}\".format(p1-p0)\n",
    "    print(\"treatment effect for subgroup sex=\", sex, \" is \", dp)\n",
    "\n",
    "d = df.groupby([\"trt\", \"y\"])[\"count\"].sum().to_dict()\n",
    "n0 = int(d[(0,0)] + d[(0,1)])\n",
    "p0 = d[(0,1)] / n0 if n0 != 0 else 0\n",
    "n1 = int(d[(1,0)] + d[(1,1)])\n",
    "p1 = d[(1,1)] / n1 if n1 != 0 else 0\n",
    "dp = \"{:.3f}\".format(p1-p0)\n",
    "print(\"treatment effect for the entire cohort is \", dp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we just look at those male patients ($X=0$), it looks like there is a clear advantage of the treatment, with about 10% more patients being cured if treated. Similarly, the treatment seems effective if we look at the subgroup of female patients ($X=1$). However, if we look at the cure rate for the entire cohort, it seems like the treatment is harmful as the treatment group yielded a lower cure rate.\n",
    "\n",
    "This might be difficult to explain with an association type of statement, yet, it might look differently from the perspective of causal inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definitions of Causality \n",
    "\n",
    "[\"Causality\"](https://plato.stanford.edu/entries/causation-metaphysics/) is a vague, philosophical sounding word. \n",
    "\n",
    "#### What Does Causality Mean?\n",
    "\n",
    "Change the value of $X$ $\\implies$ Change the distribution of $Y$ (Change the parameter or the distribution structure) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causal Models\n",
    "\n",
    "All aim to relate two type of situation:\n",
    "\n",
    "* <font color='blue'>An observational world</font>\n",
    "    * a 'natural' process assigns 'treatment'\n",
    "    * Example: each patient chooses their own treatment\n",
    "    \n",
    "* <font color='red'>An experimental world</font>\n",
    "    * 'Treatment' assigned via an 'external' process\n",
    "    * Example: each patient is given the same treatment\n",
    "    \n",
    "* In observational world\n",
    "    * <font color='red'>patient A --- takes drug X  $\\rightarrow$ cured </font>\n",
    "    * <font color='green'>patient B --- takes placebo  $\\rightarrow$ not cured </font> <br/>\n",
    "  __drug X is effective?__\n",
    "    \n",
    "    \n",
    "* In experimental world\n",
    "    * <font color='red'>patient A --- takes drug X  $\\rightarrow$ cured </font>\n",
    "    * <font color='green'>patient A --- takes placebo  $\\rightarrow$ not cured </font> <br/>\n",
    "  __drug X is effective! (at lease for patient A)__\n",
    "  \n",
    "    \n",
    "Notationwise, let us denote $X$ and $Y$ be two random variables. The \"causal effect\" of $X$ on $Y$ could be how the distribution of $Y$ will change when we force $X$ to change from one value (control?) to another (treatment?). This act of forcing a variable to take a certain value is called an \"Intervention\".\n",
    "\n",
    "In the observational world, when we make no intervention on the system, we have an observational distribution of $Y$, conditioned on the fact we observe $X$: $\\color{blue}{\\Pc Y X}$\n",
    "\n",
    "In the experimental world, we could make an intervention. The distribution of $Y$ is then given by the \"interventional\" distribution: $\\color{red}{\\Pc Y {\\hbox{do}(X)}}$\n",
    "\n",
    "In general these two are not the same.\n",
    "\n",
    "\n",
    "### Usage of Causal Models\n",
    "\n",
    "* Given observational data make predictions about what would be observed in an experimental setting\n",
    "\n",
    "* Given experimental data predict what happens in an observational context\n",
    "\n",
    "* Combine experimental and observational data to predict the result of some experiment that was not performed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different Frameworks can relate observational and experimental:\n",
    "\n",
    "\n",
    "* ### Structural Equation Models\n",
    "\n",
    "* ### Graphical Causal Models\n",
    "\n",
    "* ### Counterfactual Outcomes\n",
    "\n",
    "* ### ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structural Equation Approach\n",
    "\n",
    "* Econometrics: [Haavelmo (1943)](http://static.stevereads.com/papers_to_read/the_statistical_implications_of_a_system_of_simultaneous_equations.pdf), [Strotz & Wold (1960)](https://www.jstor.org/stable/pdf/1907731.pdf?casa_token=8D9vMMtDZH4AAAAA:zXsTdnxco8YKzg-pNLj8X5gf7NdR_mBTS8Wdv5wUxMpxSYjCtULPH5PyV-35w5WklN7ifHyAGfweyXiBbKylsExgI4aj9C1CeJze6C3oyFKzRZJqQLs) \n",
    "\n",
    "* System of equations describing the observational world\n",
    "\n",
    "* Specifies a data-generating process – with autonomous ‘mechanisms’ – for the observational distribution\n",
    "\n",
    "Simple example with covariate $L$, treatment $A$ and outcome $Y$:\n",
    "\n",
    "$L = f_L(\\epsilon_L)$\n",
    "\n",
    "$A = f_A(L, \\epsilon_A)$\n",
    "\n",
    "$Y = f_Y(L, A, \\epsilon_Y)$\n",
    "\n",
    "Individual outcomes under intervention derived by removing equations. e.g. By fixing $A$ to 0, we can obtain\n",
    "\n",
    "$L = f_L(\\epsilon_L)$\n",
    "\n",
    "$A = 0$\n",
    "\n",
    "$Y = f_Y(L, 0, \\epsilon_Y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphical Causal Models\n",
    "\n",
    "* A graphical model is a probabilistic model whose conditional (in)dependence structure between random variables is encoded by a graph. \n",
    "\n",
    "* A graph that is both directed (i.e. all edges are directed) and acyclic (i.e. contains no directed cycles) is called a Directed Acyclic Graph (DAG).\n",
    "\n",
    "We will mainly focus on the DAGs as these allow particularly simple causal interpretations. Such models are also known as Bayesian networks.\n",
    "\n",
    "<img src=\"./plots/ebmed2019June243109F1.jpg\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "Example: Causal DAG depicting a hypothetical flow of causes and effects between variables.[source:BMJ Evid Based Med. 2019 Jun;24(3):109-112](https://ebm.bmj.com/content/24/3/109)\n",
    "\n",
    "* Postulates a joint distribution over outcomes in experimental and observational settings\n",
    "\n",
    "* Typically, experimental outcomes are ‘primary’, of which observational outcomes are deterministic functions\n",
    "\n",
    "* Allows precise characterization of identification assumptions as conditional independence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Potential Outcome Framework\n",
    "\n",
    "* Introduce new random variables to the system: $Y^{a}$, known as the Potential Outcomes (the outcome if patient takes treatment $a$). \n",
    "\n",
    "* These variables can never be directly observed, but can be treated as any other random variable.\n",
    "\n",
    "* Connect to the observed variable $Y$: \n",
    "\n",
    " - $Y = Y^{a}$ when $A=a$\n",
    " \n",
    "<img src=\"./plots/twoWORLD.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    " \n",
    "* Rich language allowing many quantities of interest to be formulated, e.g. [Effect of Treatment among the treated (ETT)](https://www.nber.org/papers/t0107), [NDE](https://www.ncbi.nlm.nih.gov/pubmed/1576220)\n",
    "\n",
    "* \"Reduces\" Causation to [Missing Data](https://en.wikipedia.org/wiki/Missing_data); all outcomes ‘observable’ a priori\n",
    "\n",
    "* Allows precise characterization of identification assumptions as conditional independence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### History of Counterfactual Outcome Framework\n",
    "\n",
    "* Rubin Causal Model (RCM; Rubin 1978) is an approach to the statistical analysis of cause and effect based on the framework of potential outcomes (one of the most popular approaches in causal inference)\n",
    "* J. Neyman first used the term ‘potential outcome’ in his Master‘s thesis (1923，Polish)\n",
    "  - Neyman, Jerzy. Sur les applications de la theorie des probabilites aux experiences agricoles: Essai des principes. Master's Thesis (1923)\n",
    "* In 1990, D. M. Dabrowska, and T. P. Speed translated it and reprinted on Statistical Science   (Neyman-Rubin Model)\n",
    "  - Neyman (1990 [from 1923]) On the application of probability theory to agricultural experiments. Essay on principles. Section 9. Statistical Science 5:465-480.\n",
    "* D. Rubin (independently) brought this concept into a general framework for thinking about causation in both observational and experimental studies\n",
    "* D Rubin (1974) Estimating causal effects of treatments in randomized and nonrandomized studies. J Educational Psychology 66:688-701\n",
    "* Accoridng to J. Heckman, potential outcomes model was first proposed in economics (Roy Model)\n",
    "  - Roy, A. (1951): Some Thoughts on the Distribution of Earnings. Oxford Economic Papers 3(2), pp. 135-146.\n",
    "* D. Rubin had a short comment on Heckman’s citation in his Fisher Lecture “Causal Inference Using Potential Outcomes: Design, Modeling, Decisions” (Rubin 2005 JASA)\n",
    "  - “In the economics literature, the use of the potential outcomes notation to define causal effects has recently (e.g., Heckman 1996) been attributed to Roy (1951) or Quandt (1958), which is puzzling because neither of these articles addresses causal inference, and the former has no mathematical notation at all. For seeds of potential outcomes in economics, the earlier references cited at the start of this paragraph are much more relevant; see the rejoinder by Angrist, Imbens, and Rubin (1996) for more on this topic.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Counterfactuals \n",
    "\n",
    "* Study sample consists of patients (or subjects) indexed by $i = 1, 2, \\cdots, n$.\n",
    "\n",
    "* Define the potential outcome $Y_i^{(a_1,k_1, a_2,k_2, \\cdots, a_n, k_n)}$  to be the outcome that would be observed for the $i$th subject if each subject’s treatment $A_i$ and method of administration $k_i$ were set to $a_i$ and $k_i$, respectively, for $i = 1, 2, \\cdots, n$.\n",
    "\n",
    "* How could this be practically useful -- possible simplification:\n",
    "  \n",
    "  Stable Unit Treatment Value Assumption (__SUTVA__): \n",
    "  \n",
    "  $Y_i^{(a_1,k_1,a_2,k_2,\\cdots,a_n,k_n)}=Y_i^{a_i}$.\n",
    "\n",
    "    * No interference (units do not interfere with each other): treatment applied to one unit does not effect the outcome for another unit\n",
    "    \n",
    "    * There is only a single version of each treatment level (potential outcomes must be well defined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What does counterfactual model look like\n",
    "\n",
    "Binary treatment $A=1$ if treated / exposed, $0$ if not treated / unexposed\n",
    "\n",
    "Denote $Y^1$ the outcome if patient takes the treatment $A=1$, $Y^0$ the outcome if patient takes no treatment $A=0$\n",
    "\n",
    "While $Y$ is the true outcome\n",
    "\n",
    "For simple comparisons of outcomes with vs. without a single treatment, we let $A_i = 1$ if the treatment is given for patinet $i$ ($i=1,\\cdots,n$) and $A_i$ = 0 otherwise, and say the causal effect for the $i$th patient is $Y_i^1−Y_i^0$. \n",
    "\n",
    "* The average causal effect in the study population (ATE) is: $\\text{ATE} = E[Y_i^1 − Y_i^0]$\n",
    "\n",
    "* The average causal affect in the treated (ATT): $\\text{ATT} = E[Y_i^1 − Y_i^0\\,\\vert\\, A_i=1]$\n",
    "\n",
    "* The average causal affect in the untreated (ATU, or ATC as 'in controls'): $\\text{ATU} = E[Y_i^1 − Y_i^0\\,\\vert\\, A_i=0]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| index $i$ | $A_i$ | $Y_i$ | $Y_i^0$ | $Y_i^1$ |\n",
    "| --- | --- | --- | --- | --- | \n",
    "| 1 | 0 | 4 | 4 | ? |\n",
    "| 2 | 0 | 7 | 7 | ? |\n",
    "| 3 | 0 | 2 | 2 | ? |\n",
    "| 4 | 0 | 8 | 8 | ? |\n",
    "| 5 | 1 | 3 | ? | 3 |\n",
    "| 6 | 1 | 5 | ? | 5 |\n",
    "| 7 | 1 | 8 | ? | 8 |\n",
    "| 8 | 1 | 9 | ? | 9 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\def\\ci{\\perp\\!\\!\\!\\perp}$\n",
    "__Assumptions__ are needed to estimate the missing data in the counterfacturals:\n",
    "\n",
    "*  Consistency: $Y_i^a = Y_i$ if $A_i=a$.\n",
    "\n",
    "*  Positivity: $0 < \\Pc {A_i=1} {X_{1,i},X_{2,i},\\cdots,X_{p,i}} < 1$, for all values of $X_{1,i},X_{2,i}, \\cdots, X_{p,i}$ that occur in the study population.\n",
    "\n",
    "*  Conditional Exchangeability (No Unmeasured Confounding Assumption, NUCA): $\\{Y_i^0, Y_i^1\\} \\ci A_i \\vert \\{X_{1,i},X_{2,i}, \\cdots, X_{p,i}\\}$\n",
    "\n",
    "<img src=\"./plots/CIassumptions.png\" alt=\"Drawing\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
